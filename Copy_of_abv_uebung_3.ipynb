{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of abv-uebung-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezamdv/awesome/blob/master/Copy_of_abv_uebung_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eOYHnYxO_GXM"
      },
      "source": [
        "# X's and O's detection with a simple CNN (afg-uebung-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bAwa35fi_Ros"
      },
      "source": [
        "Please fill in\n",
        "\n",
        "**Name:** Mahdavi, Alireza\n",
        "\n",
        "**Email:** alma@uni-bremen.de\n",
        "\n",
        "**Time needed:** 2 Day"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sWbiWRtn-21d",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# from keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout \n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = 16, 25\n",
        "\n",
        "print (tf.__version__, keras.__version__)\n",
        "\n",
        "from google.colab import files  # if you use google colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s3dNJl3ILJi8"
      },
      "source": [
        "# The Dataset\n",
        "The dataset is stored in a .zip file with a .jpg file for each image and corresponding .png file for the ground-truth annotation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLOaRaMU1RFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "gtResolution = \"-quarter\" # set to \"\", \"-half\" or \"-quarter\" depending on the output resolution of your network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PkC9v3QA-75L",
        "colab": {}
      },
      "source": [
        "# Download the x-and-o.zip dataset and unzip it\n",
        "# Alternative: Set data_root if the dataset is already downloaded.\n",
        "import os\n",
        "import glob\n",
        "def loadDataset():\n",
        "    \"\"\"Download the dataset and split it in test and training. Chooses the ground-truth\n",
        "       resoltion depending on gtResolution ='', '-quarter' or ''-half' \"\"\"\n",
        "    data_root = keras.utils.get_file('x-and-o.zip','http://www.informatik.uni-bremen.de/agebv2/pub/x-and-o.zip', extract=True)\n",
        "    data_root = os.path.join(os.path.split(data_root)[0],\"x-and-o\")\n",
        "    # print(data_root)\n",
        "    # data_root = \"/root/.keras/datasets/x-and-o\" # Use this instead if the dataset is on your system\n",
        "    dataset = [(os.path.join(data_root,'x-and-o-{:03d}.jpg'.format(i)), os.path.join(data_root,'x-and-o-{:03d}-gt{:}.png'.format(i, gtResolution))) for i in range(0,1000) ]\n",
        "    dataset = [i for i in dataset if os.path.isfile(i[0]) and os.path.isfile(i[1])]\n",
        "#     print(dataset)\n",
        "    #random.shuffle(dataset)\n",
        "    nTrain = int(math.ceil(0.8*len(dataset)))\n",
        "    return dataset[0:nTrain], dataset[nTrain:]\n",
        "\n",
        "def repeatToLength(x, minLen):\n",
        "   if len(x)<minLen: x = x*math.ceil(minLen/len(x)) \n",
        "   return x\n",
        "\n",
        "train, test = loadDataset()\n",
        "print(f\"Loaded {len(train)+len(test)} images with ground-truth, {len(train)} training, {len(test)} test\")\n",
        "\n",
        "if len(test)==0: test = train.copy() # Hack if we only have one image\n",
        "train = repeatToLength (train, 100)# Hack, duplicate images, because training progress bar gets confusing otherwise\n",
        "test  = repeatToLength (test, 4)\n",
        "print(f\"Made {len(train)} training, {len(test)} test from it by duplication.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZO35KZkljsg",
        "colab": {}
      },
      "source": [
        "def loadImage(fname, color_mode='rgb'):\n",
        "  \"Loads an image as a h*w*3 numpy float array converted to [0..1] as range\"\n",
        "  return img_to_array(load_img(fname,color_mode=color_mode), dtype=\"float\")/255.0\n",
        "\n",
        "# Load the first image and get the shape of that: All images have the same size\n",
        "def shapeOfFilename(fname,color_mode='rgb'):\n",
        "  \"Returns the imageshape of fname (filename).\"\n",
        "  imageShape = loadImage(fname, color_mode=color_mode)\n",
        "  return imageShape.shape\n",
        "\n",
        "# plt.rcParams['figure.figsize'] = 16, 25\n",
        "# plt.imshow(loadImage(train[0][0]), aspect='equal', interpolation=None)\n",
        "# plt.show()\n",
        "\n",
        "imageShape = shapeOfFilename(train[0][0],color_mode='grayscale')\n",
        "print(f\"Image format {imageShape}.\")\n",
        "gtShape = shapeOfFilename(train[0][1],color_mode='rgb')\n",
        "print(f\"Ground truth format {gtShape}.\")\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BTLNvwVx4RCf",
        "colab": {}
      },
      "source": [
        "# TODO: Implement\n",
        "def annotation2PropDist (gtImage):\n",
        "  \"\"\"The ground truth images in the dataset have red and blue dots on white background.\n",
        "     This function converts such a gtImage into the format needed for training a classifier\n",
        "     with the three class (None 0 , X 1 , O 2). The format has three channels, containing the\n",
        "     probability for background, X and O respectively. The function also works with\n",
        "    mixed colors as they appear from downsizing the ground-truth image. All images have range [0..1].\n",
        "    Make sure the result does not exceet the same range.\"\"\"\n",
        "  # This function should not use loops but numpy operations, because otherwise training will\n",
        "  # become excessively slow.\n",
        "  img = np.array(gtImage)\n",
        "  h,w,_= img.shape\n",
        "  shp = h*w  \n",
        "  BG= img[:,:,1].reshape(shp,1)  #White\n",
        "  Xs=abs(BG-img[:,:,0].reshape(shp,1)) #Red\n",
        "  Os=abs(BG-img[:,:,2].reshape(shp,1)) #Blue\n",
        "  ret = np.hstack((BG,Xs,Os)).reshape(img.shape) # put all togather in orginal shape\n",
        "  return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pi1TybHXpPF_",
        "colab": {}
      },
      "source": [
        "def showImageWithOverlay (image, labels, filename=None, exaggerate=1):\n",
        "    \"\"\"Overlay the labels onto the image. labels may have a lower resolution and must have a three\n",
        "      channel format showing a probability distribution of (background,X,O). If filename is given,\n",
        "      the result is saved. The probabilities for X and O are multiplied by exaggerate to allow\n",
        "      viewing small probabilities too.\"\"\"\n",
        "    factor = image.shape[0]//labels.shape[0]\n",
        "    assert labels.shape[0]*factor==image.shape[0] and labels.shape[1]*factor==image.shape[1]\n",
        "    assert len(labels.shape)==3 and labels.shape[2]==3\n",
        "    if len(image.shape)==2: image = image[:,:,np.newaxis] # add third dimension for grayscale\n",
        "    if image.shape[-1]==1: image = np.repeat(image, 3, axis=-1) # grayscale to color\n",
        "    labelsResized = np.repeat (labels, factor, axis=0) # y\n",
        "    labelsResized = np.repeat (labelsResized, factor, axis=1) #x\n",
        "    displayImage = image * np.maximum(0,(1-exaggerate*(1-labelsResized[:,:,0,np.newaxis])))\n",
        "    displayImage[:,:,0] += exaggerate*labelsResized[:,:,1] # X-->Red\n",
        "    displayImage[:,:,2] += exaggerate*labelsResized[:,:,2] # Y-->Blue\n",
        "    np.clip(displayImage, 0, 1, out=displayImage)\n",
        "    plt.imshow (displayImage, aspect=\"equal\", interpolation=None)\n",
        "    if filename is not None:\n",
        "       plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
        "    plt.show\n",
        "    \n",
        "\n",
        "labels=annotation2PropDist(loadImage(train[0][1]))\n",
        "# Use the following to inspect individual channels of the labels image for debugging\n",
        "# \n",
        "# plt.imshow(labels)\n",
        "# plt.imshow (labels[:,:,1])#, vmin=0, vmax=1, aspect=\"equal\", interpolation=None, cmap=\"gray\")\n",
        "# plt.show\n",
        "plt.rcParams['figure.figsize'] = 16, 25\n",
        "showImageWithOverlay (loadImage(train[0][0],color_mode='grayscale'), labels)\n",
        "# labels[19][126]\n",
        "# plt.imshow(loadImage(train[0][1]))\n",
        "# plt.show()\n",
        "# np.average(labels, axis=1)\n",
        "# np.average(labels,axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfyvQnVs1RGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: implement\n",
        "def entropy(x):\n",
        "    '''Returns the average entropy of the probability distributions in x. The last axis of x\n",
        "    is assumed to represent the different events with their probabilities. Over this axis the\n",
        "    entropy is computed, all other axes create just a multitude of such distributions and over\n",
        "    these axes the average is taken.'''\n",
        "    # -(np.nansum(x*np.log(x)))/len(x)\n",
        "    return np.max(np.nan_to_num(-tf.math.cumsum(x*tf.math.log(x))))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-F-QapE1RGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Implementierung\n",
        "      # [1,0,0]\n",
        "s = np.array([[1,0,0,0], [0.5,0.5,0,0]])\n",
        "entropy(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KuGxs1c1RGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run this test to check if entropy is coded correctly\n",
        "np.testing.assert_almost_equal (entropy(np.array([[1,0,0,0], [0.5,0.5,0,0]],dtype=np.float)), math.log(2)/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oturp3OR1RGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"A perfect classifier could reach a loss of {entropy(labels)} on this dataset\")\n",
        "print(f\"A classifier not looking at the data at all could reach {entropy(np.average(labels,axis=(0,1)))} on this dataset\") \n",
        "#TODO: Comment, what loss do you expect to achieve?\n",
        "#0.009"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ORiLhxVA9EB5",
        "colab": {}
      },
      "source": [
        "# Tools to load the training / test set on the fly, so the whole dataset\n",
        "# doesn't need to be kept in memory.\n",
        "def prepareEntry (entry):\n",
        "  \"\"\"Dummy function to prepare and entry of the dataset. It takes one entry\n",
        "     and converts it to a input, ground-truth output pair that is given\n",
        "     to keras. At the moment the image is loaded and the output is just empty.\"\"\"\n",
        "  #print(f\"Loading....{entry[0]}\")\n",
        "  return (loadImage(entry[0], color_mode='grayscale').astype('float32'), annotation2PropDist(loadImage(entry[1])).astype('float32'))\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "     \"\"\"Provides a dataset to keras in a load on demand fashion. The dataset is a list\n",
        "     of entries, each of which is finally converted via prepareEntry\n",
        "     Adapted from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\"\"\"\n",
        "    \n",
        "     def __init__(self, dataset, prepareEntry=prepareEntry, batch_size=4, shuffle=True):  \n",
        "        'Initialization'\n",
        "        self.dataset = dataset\n",
        "        self.prepareEntry = prepareEntry\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "     def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.ceil(len(self.dataset) / self.batch_size))\n",
        "      \n",
        "     def __getitem__(self, index):\n",
        "          'Generate one batch of data'\n",
        "          startIdx = index*self.batch_size\n",
        "          endIdx = min(startIdx + self.batch_size, len(self.dataset))\n",
        "          batchFilenames = self.dataset[startIdx:endIdx]\n",
        "          batchData = [self.prepareEntry(e) for e in batchFilenames]\n",
        "          for e,n in zip(batchData, batchFilenames):\n",
        "            if e[0].dtype!='float32' or e[0].shape!=imageShape:\n",
        "                raise Exception(f'{n[0]} has datatype {e[0].dtype} and format {e[0].shape}')\n",
        "            if np.min(e[0])<0 or np.max(e[0])>1:\n",
        "                raise Exception(f'{n[0]} has range [{np.min(e[0])}..{np.max(e[0])}]')\n",
        "            if e[1].dtype!='float32' or e[1].shape!=gtShape:\n",
        "                raise Exception(f'{n[1]} has datatype {e[1].dtype} and format {e[1].shape}')\n",
        "            if np.min(e[1])<0 or np.max(e[1])>1:\n",
        "                raise Exception(f'{n[1]} has range [{np.min(e[1])}..{np.max(e[1])}]')\n",
        "          X = np.array([e[0] for e in batchData])\n",
        "          y = np.array([e[1] for e in batchData])\n",
        "          return X, y\n",
        "        \n",
        "     def on_epoch_end(self,logs={}):\n",
        "         'Updates indexes after each epoch'\n",
        "         if self.shuffle: random.shuffle(self.dataset)\n",
        "     def on_batch_end(self,logs={}):\n",
        "         'Updates indexes after each epoch'\n",
        "         if self.shuffle: random.shuffle(self.dataset)\n",
        "         THR = 0.0013 #Assign THR with the value at which you want to stop training.\n",
        "         currentLoss = logs.get('loss')\n",
        "         if currentLoss != None:\n",
        "            if currentLoss <= THR:\n",
        "                 self.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "guYnZPgT6YzJ",
        "colab": {}
      },
      "source": [
        "# Use this to test that the data generator works and in particular that the format,\n",
        "# datatypes and value ranges are correct\n",
        "def showEntryOfGenerator (dataGen, index=0):\n",
        "  \"\"\"Fetches the first batch, prints dataformat statistics and \n",
        "  shows the first entry both as image X and annotation y.\"\"\"\n",
        "  X, y = dataGen[index]\n",
        "  print(f\"X has shape{X.shape}, type {X.dtype} and range [{np.min(X)}..{np.max(X)}]\")\n",
        "  print(f\"y has shape{y.shape}, type {y.dtype} and range [{np.min(y)}..{np.max(y)}]\")\n",
        "  #for i in range(0,X.shape[0]):\n",
        "  #   showImageWithOverlay (X[i], y[i]) \n",
        "  #   plt.show()\n",
        "\n",
        "trainGen = DataGenerator (train)\n",
        "testGen = DataGenerator (test)\n",
        "for i in range(0,len(trainGen)):\n",
        "    \n",
        "    showEntryOfGenerator (trainGen, index=i)\n",
        "for i in range(0,len(testGen)):\n",
        "    showEntryOfGenerator (testGen, index=i)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XquvEfXnTFa7",
        "colab": {}
      },
      "source": [
        "Now construct a reasonable network (model) to solve the problem. You can start with the architecture from\n",
        "Aufgabe 2.3 (3*3-Pool-3*3-Pool-3*3), however my experiments showed that 5 channels are too few and 7 needed. Take care in the final\n",
        "layer to choose the right activation. This also may have consequences on the preceding layer als well. Also\n",
        "take care to choose the right loss and metric. In my experiments I needed about 100 epochs to get a reasonable result (Training Loss 0.015). This took several hours on my 3 GHz Intel Core i7 computer without GPU.\n",
        "Using GPU or google colab is much faster. The network was unable to detect larger Os. You might also try a somewhat larger network (more layers, more channels, maybe larger filter in the first layer).\n",
        "\n",
        "Take a look at https://keras.io/api/ for documentation and code examples.\n",
        "\n",
        "Use model.summary() to print the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rLspHx0SqH2_",
        "colab": {}
      },
      "source": [
        "# TODO: Implementierung\n",
        "lr=0.001\n",
        "model =Sequential()\n",
        "\n",
        "model.add(Conv2D( 7 , kernel_size=(3,3),data_format='channels_last'  ,activation='relu',strides=(1,1),padding='same',input_shape=(1160,820,1) ))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same',input_shape=(1160,820,7)))\n",
        "\n",
        "model.add(Conv2D( 7, kernel_size=(3,3),data_format='channels_last' ,activation='relu',strides=(1,1),padding='same',input_shape=(580,410,7)))\n",
        " \n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same',input_shape=(580,410,7)))\n",
        "\n",
        "model.add(Conv2D( 7, kernel_size=(3,3),data_format='channels_last' ,activation='relu',strides=(1,1),padding='same',input_shape=(290,205,7)))\n",
        "\n",
        "model.add(Dense(units = 3, activation = 'softmax'))\n",
        "\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(units = 128, activation = 'sigmoid'))\n",
        "# model.add(Dense(units = 3, activation = 'softmax'))\n",
        "# optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.build()\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9YdSFKkpHOiR",
        "colab": {}
      },
      "source": [
        "# Train the Network\n",
        "#model.load_weights (\"x-and-o-net.h5\"), #load a previous checkpoint\n",
        "for ctr in range(40):\n",
        "  model.fit_generator(generator=trainGen, epochs=20, validation_data=testGen)\n",
        "  model.save_weights(\"x-and-o-net.h5\") # saves weights (e.g. a checkpoint) locally\n",
        "  print(f'###### Nr.{ctr} ####### ')\n",
        "\n",
        "# files.download('x-and.o.net.h5') # download weights from e.g. google-colab to local machine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l610aw6b1RHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"x-and-o-net.h5\")\n",
        "files.download('x-and-o-net.h5') # download weights from e.g. google-colab to local machine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DxaVcVYeKuid",
        "colab": {}
      },
      "source": [
        "# Use this to visualize results\n",
        "# It shows the input image (background) and predicted heatmap (colorful labels)\n",
        "testIdx = random.randint(0,len(testGen)-1)\n",
        "testBatch = testGen[testIdx]\n",
        "plt.rcParams['figure.figsize'] = 16, 25\n",
        "print (testIdx, testBatch[0].shape)\n",
        "yHats = model.predict (testBatch[0])\n",
        "# yHats=tf.argmax(yHats)\n",
        "print(model.evaluate(testBatch[0], testBatch[1], batch_size=4))\n",
        "s = tf.argmax(yHats[0:,:,:])\n",
        "for i in range(0,len(testBatch[0])):\n",
        "   showImageWithOverlay (testBatch[0][i], yHats[i], filename=f\"x-and-o-result-{i}.png\", exaggerate=2) \n",
        "   plt.show()\n",
        "# entropy(yHats[0])\n",
        "# plt.imshow(s)\n",
        "# plt.show()\n",
        "# s[50: ,50:,0]\n",
        "# testBatch[0][1].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFUN1Hrd1RHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "channel = 0\n",
        "np.max(yHats[0,:,:,channel]) # Use this to inspect maximum probability for Nothing (channel 0), X (1) or O (2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTghA7eX1RHj",
        "colab_type": "text"
      },
      "source": [
        "Give a comment on the performance of your network (can be German).\\\n",
        "'zuerst versuchte ich, die annotation2propdist mit numpy **mask** zu implementieren(war gar nicht gut mit dem quarter Bild) und dann mit numpy **apply_along_axis**, aber es war nicht schnell genug... mit der aktuellen Implementierung, nämlich Numpy **slicing**, konnte ich es für 800 Epochen laufen lassen und ich denke, die Performance ist wirklich sehr gut.'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIsAp1h61RHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}